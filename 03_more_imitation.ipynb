{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'background': '#ff0000',\n",
       " 'height': 768,\n",
       " 'progress': 'true',\n",
       " 'scroll': 'true',\n",
       " 'start_slideshow_at': 'selected',\n",
       " 'theme': 'solarized',\n",
       " 'transition': 'slide',\n",
       " 'width': 1024}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.html.services.config import ConfigManager\n",
    "from IPython.paths import locate_profile\n",
    "cm = ConfigManager(profile_dir=locate_profile(get_ipython().profile))\n",
    "cm.update('livereveal', {\n",
    "              'theme': 'solarized',\n",
    "              'transition': 'slide',\n",
    "              'start_slideshow_at': 'selected',\n",
    "              'progress': 'true',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<h2>Interpretation and connections</h2>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Why does IL work?\n",
    "\n",
    "A bit of theory (Goodman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reinforcement learning\n",
    "\n",
    "<p style=\"float: left;\">\n",
    "<ul style=\"float: left;\">\n",
    "<li>states defined via features</li>\n",
    "<li>the agent is a classifier</li>\n",
    "<li>rewards?</li>\n",
    "</ul>\n",
    "</p>\n",
    "\n",
    "<a href=\"https://webdocs.cs.ualberta.ca/~sutton/book/ebook/node28.html\"><img src=\"images/RL_sutton.png\" style=\"width:44%; float: right;\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Inverse reinforcement learning**\n",
    "\n",
    "- we have the expert policy (inferred from the gold standard in the training data)\n",
    "- we infer the per-action reward function (rollin/out)\t\t\t\t\n",
    "\n",
    "\n",
    "Replacing the expert policy in LoLS with a random (sub-optimal) one is RL ([Chang et al., 2015](https://arxiv.org/pdf/1502.02206.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Inverse reinforcement learning\n",
    "\n",
    "- and learn a policy (classifier) to generalize to unseen data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Bandit learning\n",
    "\n",
    "Sokolov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Semi/Unsupervised learning\n",
    "\n",
    "Learning with non-decomposable loss functions means\n",
    "- no need to know the correct actions\n",
    "- learn to predict them in order to minimize the loss\n",
    "\n",
    "<img src=\"images/tikz/semParse.png\" style=\"width:100%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "UNSEARN ([Daumé III, 2009](http://www.umiacs.umd.edu/~hal/docs/daume09unsearn.pdf)): Predict the structured output so that you can predict the input from it (auto-encoder!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Negative data sampling\n",
    "\n",
    "<img src=\"images/tikz/posImitClassifierTraining.png\" style=\"width:65%; align:left;\">\n",
    "\n",
    "- Expert action sequence → positive example\n",
    "- All other action sequences → negative examples\n",
    "- Using all negative examples inefficient\n",
    "\n",
    "Imitation learning: generate negative samples around the expert "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A form of **Adversarial training** ([Ho and Ermon, 2016](https://arxiv.org/abs/1606.03476)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Coaching\n",
    "\n",
    "<p style=\"float: left;\">If the optimal action is difficult<br>to predict, the coach teaches<br>a good one that is easier<br> (<a href=\"https://papers.nips.cc/paper/4545-imitation-learning-by-coaching.pdf\">He et al., 2012</a>)</p> <a href=\"https://commons.wikimedia.org/wiki/File:US_Navy_091206-N-2013O-023_Sam_Givens,_a_player_for_the_Harlem_Ambassadors_basketball_team,_demonstrates_proper_dribbling_techniques_to_a_boy_during_a_basketball_camp_sponsored_by_Yokosuka%27s_Morale,_Welfare_and_Recreation_Youth.jpg\"><img src=\"images/coaching.jpg\" style=\"width:35%; float: right;\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Expert: $\\alpha^{\\star}= \\mathop{\\arg \\min}_{\\alpha \\in {\\cal A}} L(S_t(\\alpha,\\pi^{\\star}),\\mathbf{y})$\n",
    "\n",
    "Coach: $\\alpha^{\\star}= \\mathop{\\arg \\min}_{\\alpha \\in {\\cal A}} L(S_t(\\alpha,\\pi^{\\star}),\\mathbf{y}) - \\lambda f(\\alpha, \\mathbf{x}, S_t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Ranking\n",
    "\n",
    "Jana Rao Doppa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3> What about Recurrent Neural Networks?</h3>\n",
    "\n",
    "<img src=\"images/rnn.png\" width=\"70%\"  style=\"background:none;\" />\n",
    "\n",
    "<p>They face similar problems:\n",
    "\t\t\t\t<ul>\n",
    "\t\t\t\t<li>trained at the word rather than sentence level</li>\n",
    "\t\t\t\t<li>assume previous predictions are correct</li>\n",
    "\t\t\t</ul>\n",
    "\t\t\t</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Imitation learning and RNNs\n",
    "\n",
    "<img src=\"images/mixer.png\" width=\"70%\"  style=\"background:none;\" />\n",
    "\n",
    "\n",
    "- DAgger mixed rollins, similar to scheduled sampling ([Bengio et al., 2015](http://arxiv.org/abs/1506.03099))\n",
    "- no rollouts, learn a  regressor to estimate action costs\n",
    "- end-to-end back propagation through the sequence\n",
    "- MIXER  (<a href=\"https://arxiv.org/abs/1511.06732\">Ranzato et al., 2016</a>): Mix REINFORCE-ment learning with imitation: we have the expert policy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Actor critic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary so far\n",
    "\n",
    "- basic concepts\n",
    "  - loss function decomposability\n",
    "  - expert policy\n",
    "- imitation learning\n",
    "    - rollin/outs\n",
    "    - DAgger algorithm\n",
    "    - DAgger with rollouts and LoLS\n",
    "- connections and interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### After the break\n",
    "\n",
    "- Applications:\n",
    "  - dependency parsing\n",
    "  - natural language generation\n",
    "  - semantic parsing\n",
    "- Practical advice\n",
    "    - making things faster\n",
    "    - debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "\n",
    "<h1>Break!</h1>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
