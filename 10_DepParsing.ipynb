{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### First part recap ###\n",
    "\n",
    "Imitation Learning\n",
    "- DAgger and LOLS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Meta-learning framework, over an existing classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In practice, generates more (and better) training data, to improve the existing classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For applied Imitation Learning we need to define:\n",
    "- Transition system\n",
    "- Loss function\n",
    "- Expert policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Part 2: NLP Applications and practical advice\n",
    "\n",
    "- Applications:\n",
    "    - Dependency parsing \n",
    "    - Natural language generation\n",
    "    - Semantic parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Practical advice\n",
    "    - Expert policy definition\n",
    "    - Accelerating cost estimation\n",
    "    - Trouble-shooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<h2>Applying Imitation Learning on Dependency Parsing</h2>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dependency parsing ###\n",
    "###### ([Goldberg and Nivre 2012](http://www.aclweb.org/anthology/C12-1059), [Goldberg and Nivre 2013](https://www.aclweb.org/anthology/Q/Q13/Q13-1033.pdf)) ###### \n",
    "\n",
    "<img src=\"images/toBeAnimated/depParse1.png\">\n",
    "\n",
    "To represent the syntax of a sentence as directed labeled edges between words.\n",
    "- Where labels represent dependencies between words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What would we like to improve? ###\n",
    "\n",
    "Transition suffers from error propagation:\n",
    "- Due to the greedy decoding of the incremental model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The first error will confuse the classifier, since the resulting state was not encountered during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- More errors are likely to follow, as we move into increasingly more foreign states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How can Imitation Learning help with that? ### \n",
    "\n",
    "Imitation Learning addresses error propagation:\n",
    "- It considers the interaction between the action being considered and later actions in the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Explores the unknown search space, but avoids enumerating all possible outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It also learns how to recover from errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Before applying Imitation Learning ###\n",
    "\n",
    "For each task, we need to define:\n",
    "- Transition system\n",
    "- Loss function\n",
    "- Expert policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transition system? ###\n",
    "\n",
    "We can assume any of the proposed transition-based systems (Arc-Eager, Arc-Standard, Easy-First, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In essence, the actions regard which nodes to consider, and which arc and label to add next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transition-based dependency parsing in action! ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/transitionEx_1.png\">\n",
    "\n",
    "<b>Stack:</b> -\n",
    "<br>\n",
    "<b>Buffer:</b> ROOT, 'economic', 'news', 'had', 'little', 'effect', 'on', 'financial', 'markets', '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transition-based dependency parsing in action! ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/transitionEx_1.png\">\n",
    "\n",
    "<b>Stack:</b> ROOT\n",
    "<br>\n",
    "<b>Buffer:</b> 'economic', 'news', 'had', 'little', 'effect', 'on', 'financial', 'markets', '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transition-based dependency parsing in action! ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/transitionEx_1.png\">\n",
    "\n",
    "<b>Stack:</b> ROOT, 'economic'\n",
    "<br>\n",
    "<b>Buffer:</b> 'news', 'had', 'little', 'effect', 'on', 'financial', 'markets', '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transition-based dependency parsing in action! ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/transitionEx_2.png\">\n",
    "\n",
    "<b>Stack:</b> ROOT\n",
    "<br>\n",
    "<b>Buffer:</b> 'news', 'had', 'little', 'effect', 'on', 'financial', 'markets', '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transition-based dependency parsing in action! ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/transitionEx_2.png\">\n",
    "\n",
    "<b>Stack:</b> ROOT, 'news'\n",
    "<br>\n",
    "<b>Buffer:</b> 'had', 'little', 'effect', 'on', 'financial', 'markets', '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transition-based dependency parsing in action! ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/transitionEx_3.png\">\n",
    "\n",
    "<b>Stack:</b> ROOT\n",
    "<br>\n",
    "<b>Buffer:</b>'had', 'little', 'effect', 'on', 'financial', 'markets', '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transition-based dependency parsing in action! ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/depParse1.png\">\n",
    "\n",
    "<b>Stack:</b> ROOT\n",
    "<br>\n",
    "<b>Buffer:</b> -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Loss function? ###\n",
    "\n",
    "Hamming loss: the number of incorrectly predicted labeled or unlabeled dependency arcs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Directly related to the attachment score metrics used to evaluate dependency parsers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Expert policy? ###\n",
    "\n",
    "<center>\n",
    "<img src=\"images/oracle-delphi.jpg\">\n",
    "</center>\n",
    "\n",
    "By consulting the gold reference graphs:\n",
    "- We can easily derive a <b> single static canonical </b> sequence of actions from initial to terminal state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Static expert policies (π*) can work well for tasks where we do not care whether the previous actions were optimal or not.\n",
    "- e.g. for the Part-of-Speech tagging task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But they can be quite restricting in tasks where a suboptimal action can have negative effect on future actions.\n",
    "- i.e. tasks with error propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Deterministic policy? But what if there are multiple correct transitions? ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/depParse_2.png\">\n",
    "\n",
    "<b>Stack:</b> 'her'\n",
    "<br>\n",
    "<b>Buffer:</b> 'a', 'letter', '.'\n",
    "\n",
    "We can either: <i>reduce 'her'</i> or <i>shift 'a'</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How to chose?\n",
    "- A deterministic policy may arbitarilly chose a transition (e.g. prioritize shifts over other actions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Why chose?\n",
    "- Chosing any one action indirectly labels the alternative actions as incorrect!\n",
    "- Which introduces noise in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### And what if a mistake happens? ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/depParse_mistake_1.png\">\n",
    "\n",
    "<b>Stack:</b> 'wrote'\n",
    "<br>\n",
    "<b>Buffer:</b> 'her', 'a', 'letter', '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### And what if a mistake happens? ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/depParse_mistake_2.png\">\n",
    "\n",
    "<b>Stack:</b> 'wrote', 'her'\n",
    "<br>\n",
    "<b>Buffer:</b> 'a', 'letter', '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The static policy assumes all the past actions are optimal.\n",
    "- It is undefined for states that are not part of the gold action of sequences,\n",
    "- and thus cannot recover from mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### And what if a mistake happens? ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/depParse3.png\">\n",
    "\n",
    "Worst case scenario: it will only perform actions in states it recognizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dynamic policy ###\n",
    "\n",
    "i.e. non-deterministic and complete policy.\n",
    "- Allows for ambiguous transitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Defined for all states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Recovers from errors.\n",
    "  \n",
    "<img src=\"images/toBeAnimated/depParse4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How does a dynamic expert policy work then? ###\n",
    "\n",
    "Given a particular state, where an error may or may not have already occured:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We need to determine the set of actions that lead from this state to the best reachable terminal state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Quite possibly not an optimal terminal state, if we have made an error before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Considered \"best\" according to some loss function, and in relation to the optimal terminal state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The loss function used by the expert policy may not be the same as the overall task loss function.\n",
    "- To save computation time, when calculating the expert policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Expert policy in action! ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/depParse3.png\">\n",
    "\n",
    "\n",
    "<b>Stack:</b> 'wrote', 'her'\n",
    "<br>\n",
    "<b>Buffer:</b> 'letter', '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Expert policy in action! ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/depParse_expActions.png\">\n",
    "\n",
    "\n",
    "<b>Stack:</b> 'wrote', 'her'\n",
    "<br>\n",
    "<b>Buffer:</b> 'letter', '.'\n",
    "\n",
    "The dynamic expert policy will consider all possible (even erroneous) actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Expert policy in action! ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/depParse4.png\">\n",
    "\n",
    "Trying to find the action that leads to the best reachable terminal state. \n",
    "- A loss of 1, if we use the labeled attachment score as a loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###  Applying Imitation Learning ###\n",
    "\n",
    "[Goldberg and Nivre (2013)](https://www.aclweb.org/anthology/Q/Q13/Q13-1033.pdf) proposed a system that employed dynamic expert policies for dependency parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As well as an algorithm to learn parameters by exploration.\n",
    "\n",
    "- Very similar to DAgger.\n",
    "  - Roll-in is a mix of the learned and expert policies, at the step level.\n",
    "  - There may be multiple correct actions at each time-step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Effect of k and p ###\n",
    "<img src=\"images/dependHeatMaps.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Results ###\n",
    "<img src=\"images/dependResults.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Summary so far ### \n",
    "\n",
    "We discussed modifications to the DAgger framework.\n",
    "- Hard decay schedule after $k$ epochs when determining the roll-in and roll-out policies.\n",
    "- Using a mix of expert and learned policy during roll-outs.\n",
    "\n",
    "We showed that dynamic oracles improves on the results of static orcales."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "livereveal": {
   "height": 768,
   "start_slideshow_at": "selected",
   "theme": "solarized",
   "transition": "slide",
   "width": 1024
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
