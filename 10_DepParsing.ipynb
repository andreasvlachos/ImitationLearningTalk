{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### First part recap ###\n",
    "\n",
    "Imitation Learning\n",
    "- DAgger and LOLS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Meta-learning framework, over an existing classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In practice, generates more (and better) training data, to improve the existing classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For applied Imitation Learning we need to define:\n",
    "- Transition system\n",
    "- Loss function\n",
    "- Expert policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Part 2: NLP Applications and practical advice\n",
    "\n",
    "- Applications:\n",
    "    - Dependency parsing \n",
    "    - Natural language generation\n",
    "    - Semantic parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Practical advice\n",
    "    - Expert policy definition\n",
    "    - Accelerating cost estimation\n",
    "    - Trouble-shooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<h2>Applying Imitation Learning on Dependency Parsing</h2>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dependency parsing ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/depParse1.png\">\n",
    "\n",
    "To represent the syntax of a sentence as directed labeled edges between words.\n",
    "- Where labels represent dependencies between words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### What would we like to improve? ###\n",
    "\n",
    "Transition suffers from error propagation:\n",
    "- Due to the greedy decoding of the incremental model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- The first error will confuse the classifier, since the resulting state was not encountered during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- More errors are likely to follow, as we move into increasingly more foreign states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### How can Imitation Learning help with that? ### \n",
    "\n",
    "Imitation Learning addresses error propagation:\n",
    "- It considers the interaction between the action being considered and later actions in the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- Explores the unknown search space, but avoids enumerating all possible outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- It also learns how to recover from errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###  Applying Imitation Learning ###\n",
    "\n",
    "[Goldberg and Nivre 2012](http://www.aclweb.org/anthology/C12-1059), [Goldberg and Nivre 2013](https://www.aclweb.org/anthology/Q/Q13/Q13-1033.pdf) proposed an Imitation Learning system for dependency parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Very similar to DAgger.\n",
    "- There may be multiple correct actions at each time-step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### DAgger Reminder ###\n",
    "\n",
    "<p style=\"border:3px; border-radius: 25px; background-color:lightgrey; border-style:solid; border-color:black; padding: 0.3em; font-size: 80%\">\n",
    "\\begin{align}\n",
    "& \\textbf{Input:} \\; D_{train} = \\{(\\mathbf{x}^1,\\mathbf{y}^1)...(\\mathbf{x}^M,\\mathbf{y}^M)\\}, \\; expert\\; \\pi^{\\star}, \\; loss \\; function \\; L,\\\\\n",
    "& classifier \\; H,\\; training\\; examples\\; \\cal E = \\emptyset, \\; expert\\; probability\\; \\beta=1\\\\\n",
    "& \\mathbf{while}\\; \\text{termination condition not reached}\\; \\mathbf{do}\\\\\n",
    "& \\quad \\text{set} \\; rollin \\; policy \\; \\pi^{in} = \\beta + (1-\\beta)\\pi^{\\star}\\\\\n",
    "& \\quad \\mathbf{for} \\; (\\mathbf{x},\\mathbf{y}) \\in D_{train} \\; \\mathbf{do}\\\\\n",
    "& \\quad \\quad \\text{rollin to predict} \\; \\hat \\alpha_1\\dots\\hat \\alpha_T  = \\pi^{in}(\\mathbf{x},\\mathbf{y})\\\\\n",
    "& \\quad \\quad \\mathbf{for} \\; \\hat \\alpha_t \\in \\hat \\alpha_1\\dots\\hat \\alpha_T \\; \\mathbf{do}\\\\\n",
    "& \\quad \\quad \\quad \\text{ask expert for best action}\\; \\alpha^{\\star} = \\pi^{\\star}(\\mathbf{x},S_{t-1}) \\\\\n",
    "& \\quad \\quad \\quad \\text{extract } features=\\phi(\\mathbf{x},S_{t-1}) \\\\\n",
    "& \\quad \\quad \\quad \\cal E = \\cal E \\cup (features,\\alpha^{\\star})\\\\\n",
    "& \\quad \\text{learn classifier} \\; \\text{from}\\; \\cal E\\\\\n",
    "& \\quad \\text{decrease} \\; \\beta\\\\\n",
    "\\end{align}\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Before applying Imitation Learning ###\n",
    "\n",
    "For each task, we need to define:\n",
    "- Transition system\n",
    "- Loss function\n",
    "- Expert policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transition system? ###\n",
    "\n",
    "We can assume any of the proposed transition-based systems (e.g. Arc-Eager)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The length of the transition system is variable.\n",
    "  - vs. POS tagging where it is fixed to the length of the sentence.\n",
    "\n",
    "- The state consists of the already inserted arcs, a stack to keep track of the nodes under examination, and a buffer with the unexamined nodes.\n",
    "\n",
    "- Action space for Arc-Eager consists of Shift, Reduce, Arc-Left, and Arc-Right actions.\n",
    "  - Arc-Left and Arc-Right are further conditioned by particular labels,\n",
    "  - but there is a limited number of labels in dependency parsing (#)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transition-based dependency parsing in action! ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/transitionEx_1.png\">\n",
    "\n",
    "<b>Stack:</b> -\n",
    "<br>\n",
    "<b>Buffer:</b> ROOT, 'economic', 'news', 'had', 'little', 'effect', 'on', 'financial', 'markets', '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transition-based dependency parsing in action! ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/transitionEx_1.png\">\n",
    "\n",
    "<b>Stack:</b> ROOT\n",
    "<br>\n",
    "<b>Buffer:</b> 'economic', 'news', 'had', 'little', 'effect', 'on', 'financial', 'markets', '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transition-based dependency parsing in action! ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/transitionEx_1.png\">\n",
    "\n",
    "<b>Stack:</b> ROOT, 'economic'\n",
    "<br>\n",
    "<b>Buffer:</b> 'news', 'had', 'little', 'effect', 'on', 'financial', 'markets', '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transition-based dependency parsing in action! ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/transitionEx_2.png\">\n",
    "\n",
    "<b>Stack:</b> ROOT\n",
    "<br>\n",
    "<b>Buffer:</b> 'news', 'had', 'little', 'effect', 'on', 'financial', 'markets', '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transition-based dependency parsing in action! ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/transitionEx_2.png\">\n",
    "\n",
    "<b>Stack:</b> ROOT, 'news'\n",
    "<br>\n",
    "<b>Buffer:</b> 'had', 'little', 'effect', 'on', 'financial', 'markets', '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transition-based dependency parsing in action! ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/transitionEx_3.png\">\n",
    "\n",
    "<b>Stack:</b> ROOT\n",
    "<br>\n",
    "<b>Buffer:</b>'had', 'little', 'effect', 'on', 'financial', 'markets', '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transition-based dependency parsing in action! ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/depParse1.png\">\n",
    "\n",
    "<b>Stack:</b> ROOT\n",
    "<br>\n",
    "<b>Buffer:</b> -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Loss function? ###\n",
    "\n",
    "Hamming loss: given the predicted arcs, how many parents were incorrectly predicted. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Directly corresponds to the attachment score metrics used to evaluate dependency parsers.\n",
    "- Decomposable? No, when using this transition model! We cannot score shift actions independent of the arc actions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Expert policy? ###\n",
    "\n",
    "<center>\n",
    "<img src=\"images/oracle-delphi.jpg\">\n",
    "</center>\n",
    "\n",
    "By consulting the gold reference graphs:\n",
    "- We can easily derive a <b> single static canonical </b> sequence of actions from initial to terminal state, to form a static expert policy.\n",
    "\n",
    "LABEL TRANSITION EXAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A static expert is only defined on states visited through the single static canonical sequence of actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The static policy assumes all the past actions are optimal.\n",
    "- It is suboptimal for states that are not part of the static action of sequences,\n",
    "  - In our example, it defaults to shift actions. \n",
    "- and thus cannot recover from mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Static expert policies (π*) can work well for tasks where we do not care whether the previous actions were optimal or not.\n",
    "- e.g. for the Part-of-Speech tagging task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Static policy? But what if there are multiple correct transitions? ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/depParse_2.png\">\n",
    "\n",
    "<b>Stack:</b> 'her'\n",
    "<br>\n",
    "<b>Buffer:</b> 'a', 'letter', '.'\n",
    "\n",
    "We can either: <i>reduce 'her'</i> or <i>shift 'a'</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How to chose?\n",
    "- A deterministic policy may arbitarilly chose a transition (e.g. prioritize shifts over other actions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Why chose?\n",
    "- Chosing any one action indirectly labels the alternative actions as incorrect!\n",
    "- Which introduces noise in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### And what if a mistake happens by the learned policy during the rollin? ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/depParse_mistake_1.png\">\n",
    "\n",
    "<b>Stack:</b> 'wrote'\n",
    "<br>\n",
    "<b>Buffer:</b> 'her', 'a', 'letter', '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### And what if a mistake happens? ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/depParse_mistake_2.png\">\n",
    "\n",
    "<b>Stack:</b> 'wrote', 'her'\n",
    "<br>\n",
    "<b>Buffer:</b> 'a', 'letter', '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### And what if a mistake happens? ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/depParse3.png\">\n",
    "\n",
    "Worst case scenario: it will only perform actions in states it recognizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How does a dynamic expert policy work then? ###\n",
    "\n",
    "We need to determine the set of actions that lead from this state to the best reachable terminal state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Quite possibly not an optimal terminal state, if we have made an error before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Considered \"best\" according to some loss function, and in relation to the optimal terminal state.\n",
    "\n",
    "For each possible action:\n",
    "- perform a roll-out till the terminal state.\n",
    "- score the state according to the loss function.\n",
    "- return the set of actions that lead to the best reachable terminal state.\n",
    "\n",
    "Or we can heuristically infer an action sequence by comparing to the gold standard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "MOVE TO NLG\n",
    "\n",
    "The loss function used by the expert policy may not be the same as the overall task loss function.\n",
    "- To save computation time, when calculating the expert policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Expert policy in action! ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/depParse3.png\">\n",
    "\n",
    "\n",
    "<b>Stack:</b> 'wrote', 'her'\n",
    "<br>\n",
    "<b>Buffer:</b> 'letter', '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Expert policy in action! ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/depParse_expActions.png\">\n",
    "\n",
    "\n",
    "<b>Stack:</b> 'wrote', 'her'\n",
    "<br>\n",
    "<b>Buffer:</b> 'letter', '.'\n",
    "\n",
    "The dynamic expert policy will consider all possible (even erroneous) actions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Expert policy in action! ###\n",
    "\n",
    "<img src=\"images/toBeAnimated/depParse4.png\">\n",
    "\n",
    "Trying to find the action that leads to the best reachable terminal state. \n",
    "- A loss of 1, if we use the labeled attachment score as a loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dynamic policy ###\n",
    "\n",
    "- Allows for different transitions to reach the optimal state.\n",
    "- Recovers from errors of the learned policy.\n",
    "\n",
    "Imitation learning assumes a dynamic policy.\n",
    "- Otherwise, it cannot explore alternative actions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Effect of k and p ###\n",
    "<img src=\"images/dependHeatMaps.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Results ###\n",
    "<img src=\"images/dependResults.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Summary so far ### \n",
    "\n",
    "We discussed modifications to the DAgger framework.\n",
    "- Hard decay schedule after $k$ epochs when determining the roll-in and roll-out policies.\n",
    "- Using a mix of expert and learned policy during roll-outs.\n",
    "\n",
    "We showed that dynamic oracles improves on the results of static orcales."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "livereveal": {
   "height": 768,
   "start_slideshow_at": "selected",
   "theme": "solarized",
   "transition": "slide",
   "width": 1024
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
