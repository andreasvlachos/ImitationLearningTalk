{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<h2>Applying Imitation Learning on Semantic Parsing</h2>\n",
    "<h3>[Goodman et al. 2016](http://aclweb.org/anthology/P16-1001)</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Semantic parsing ###\n",
    "\n",
    "Semantic parsers map natural language to meaning representations.\n",
    "- Need to abstract over syntactic phenomena, \n",
    "- resolve anaphora, \n",
    "- and eliminate ambiguity in language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Essentially the inverted task of NLG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Abstract meaning representation ###\n",
    "###### ([Banarescu et al. 2013](http://www.aclweb.org/anthology/W13-2322)) ###### \n",
    "\n",
    "<div style=\"width:60%; float:left;\">\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "A MR formalism where concept <br><br>relations are represented in a DAG.\n",
    "<ul><li class=\"fragment\" data-fragment-index=\"1\">Abstracts away from function words, and inflection.</li>\n",
    "<br><li class=\"fragment\" data-fragment-index=\"2\">Transition-based approaches are common.</li></ul>\n",
    "<br>\n",
    "<br>\n",
    "<span class=\"fragment\" data-fragment-index=\"3\">[AMR tutorial by Schneider et al. 2015](https://github.com/nschneid/amr-tutorial/tree/master/slides)</span>\n",
    "</div>\n",
    "\n",
    "<img src=\"images/amrExample.png\" style=\"width:40%; float: right;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Transition system? ###\n",
    "\n",
    "We consider a dependency tree as input.\n",
    "- Dependency tree is derived from input sentence.\n",
    "\n",
    "<span class=\"fragment\" data-fragment-index=\"1\"><b>State:</b> nodes, arcs, $\\sigma$ and $\\beta$ stacks.</span>\n",
    "<ul><li class=\"fragment\" data-fragment-index=\"3\">In intermediate states, nodes may be labeled either with words, or AMR concepts.</li></ul>\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><h3><span style=\"font-variant: small-caps; color:white;\"> E </span></h3>\n",
    "<img src=\"images/toBeAnimated/parse2amr_1.png\"></center>\n",
    "<font size=\"5\">\n",
    "<b>$\\sigma$:</b> struck, by, attacks, cyber, in, 2007\n",
    "<br>\n",
    "<b>$\\beta$:</b> -\n",
    "</font>\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><h3><span style=\"font-variant: small-caps;\">Insert:</span> date-entity</h3>\n",
    "<img src=\"images/toBeAnimated/parse2amr_2.png\"></center>\n",
    "<font size=\"5\">\n",
    "<b>$\\sigma$:</b> struck, by, attacks, cyber, in, date-entity\n",
    "<br>\n",
    "<b>$\\beta$:</b> -\n",
    "</font>\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><h3><span style=\"font-variant: small-caps;\">ReplaceHead:</span> in</h3>\n",
    "<img src=\"images/toBeAnimated/parse2amr_3.png\"></center>\n",
    "<font size=\"5\">\n",
    "<b>$\\sigma$:</b> struck, by, attacks, cyber\n",
    "<br>\n",
    "<b>$\\beta$:</b> -\n",
    "</font>\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><h3><span style=\"font-variant: small-caps;\">Reattach:</span> date-entity</h3>\n",
    "<img src=\"images/toBeAnimated/parse2amr_4.png\"></center>\n",
    "<font size=\"5\">\n",
    "<b>$\\sigma$:</b> struck, by, attacks\n",
    "<br>\n",
    "<b>$\\beta$:</b> -\n",
    "</font>\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><h3><span style=\"font-variant: small-caps;\">ReplaceHead:</span> by </h3>\n",
    "<img src=\"images/toBeAnimated/parse2amr_5.png\"></center>\n",
    "<font size=\"5\">\n",
    "<b>$\\sigma$:</b> -\n",
    "<br>\n",
    "<b>$\\beta$:</b> -\n",
    "</font>\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Action space ###\n",
    "\n",
    "<div style=\"width:70%; float:left;\">\n",
    "<br>\n",
    "<br>\n",
    "Actions combine with labels<br><br>(PropBank framesets).<ul><li class=\"fragment\" data-fragment-index=\"4\">#labels in the order of 10<sup>3</sup> to 10<sup>4</sup>.</li><li class=\"fragment\" data-fragment-index=\"5\">Performing rollouts for all actions may be time-consuming.</li></ul></div>\n",
    "<img src=\"images/amrActions.png\" style=\"width:30%; float: right;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The length of the transition sequence is variable. <ul><li>In the range of 50-200 actions.</li><li class=\"fragment\" data-fragment-index=\"2\">Need to prevent cycles between state transitions!</li>\n",
    "<br>\n",
    "<span class=\"fragment\" data-fragment-index=\"2\" style=\"font-variant: small-caps;\">... -> Swap($e_i$, $e_j$) -> Swap($e_j$, $e_i$) -> ...</span></ul>\n",
    "<br>\n",
    "<br>\n",
    "<span class=\"fragment\" data-fragment-index=\"3\">Also, transition system to preserve acyclicity and <br><br> full connectivity in the graph.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Loss function? ###\n",
    "\n",
    "<b>Smatch</b> ([Cai and Knight, 2013](http://amr.isi.edu/smatch-13.pdf))\n",
    "<br>\n",
    "<ul>\n",
    "<li> F<sub>1</sub>-Score between predicted and gold standard AMR. </li>\n",
    "<li class=\"fragment\" data-fragment-index=\"1\">Calculates all possible mappings of nodes.</li>\n",
    "<li class=\"fragment\" data-fragment-index=\"2\">Computationally expensive for every rollout<br>(NP-complete).</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<b>Naive Smatch</b> employs heuristics.\n",
    "<br>\n",
    "<ul>\n",
    "<li class=\"fragment\" data-fragment-index=\"2\"> How many labels and edges in the predicted and gold standard are not present in both? </li>\n",
    "<li class=\"fragment\" data-fragment-index=\"3\"> Decomposable? <span class=\"fragment\" data-fragment-index=\"4\"><b>No!</b></span></li>\n",
    "<br><br>\n",
    "<li class=\"fragment\" data-fragment-index=\"7\"> To encourage short sequences, <br> a length penalty is applied to the loss.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Expert policy? ###\n",
    "\n",
    "A set of heuristic rules, based on alignments between nodes in dependency tree and AMR graph.\n",
    "<ul>\n",
    "<li>Mapped nodes and edges may need to be renamed.</li>\n",
    "<li>Unmapped nodes may need to be inserted or deleted.</li>\n",
    "<br><br>\n",
    "<li class=\"fragment\" data-fragment-index=\"5\"> Suboptimal? <span class=\"fragment\" data-fragment-index=\"6\"><b>Yes!</b></span></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### V-DAgger reminder ###\n",
    "\n",
    "<p style=\"border:3px; border-radius: 25px; background-color:lightgrey; border-style:solid; border-color:black; padding: 0.3em; font-size: 70%\">\n",
    "\\begin{align}\n",
    "& \\textbf{Input:} \\; D_{train} = \\{(\\mathbf{x}^1,\\mathbf{y}^1)...(\\mathbf{x}^M,\\mathbf{y}^M)\\}, \\; expert\\; \\pi^{\\star}, \\; loss \\; function \\; L, \\\\\n",
    "& \\quad \\quad \\quad learning\\; rate\\; p\\\\\n",
    "& \\text{set} \\; training\\; examples\\; \\cal E = \\emptyset \\\\\n",
    "& \\mathbf{while}\\; \\text{termination condition not reached}\\; \\mathbf{do}\\\\\n",
    "& \\quad \\color{red}{\\beta = (1 - p)^i}\\\\\n",
    "& \\quad \\color{red}{\\text{set} \\; rollin/out \\; policy \\; \\pi^{in/out} = (1-\\beta) H + \\beta \\pi^{\\star}}\\\\\n",
    "& \\quad \\mathbf{for} \\; (\\mathbf{x},\\mathbf{y}) \\in D_{train} \\; \\mathbf{do}\\\\\n",
    "& \\quad \\quad \\text{rollin to predict} \\; \\hat \\alpha_1\\dots\\hat \\alpha_T  = \\pi^{in/out}(\\mathbf{x},\\mathbf{y})\\\\\n",
    "& \\quad \\quad \\mathbf{for} \\; \\hat \\alpha_t \\in \\hat \\alpha_1\\dots\\hat \\alpha_T \\; \\mathbf{do}\\\\\n",
    "& \\quad \\quad \\quad \\mathbf{for} \\; \\alpha \\in {\\cal A} \\; \\mathbf{do}\\\\\n",
    "& \\quad \\quad \\quad \\quad \\text{rollout} \\; S_{final} = \\pi^{in/out}(S_{t-1}, \\alpha, \\mathbf{x})\\\\\n",
    "& \\quad \\quad \\quad \\quad cost\\; c_{\\alpha}=L(S_{final}, \\mathbf{y})\\\\\n",
    "& \\quad \\quad \\quad \\text{extract } features=\\phi(\\mathbf{x}, S_{t-1}) \\\\\n",
    "& \\quad \\quad \\quad \\cal E = \\cal E \\cup (features,\\mathbf{c})\\\\\n",
    "& \\quad \\text{learn classifier} \\; \\text{from}\\; \\cal E\\\\\n",
    "\\end{align}\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exploration variations ###\n",
    "\n",
    "<center>\n",
    "<img src=\"images/targetedExploration.png\">\n",
    "</center>\n",
    "\n",
    "Rollout for 50-200 time-steps, and 10<sup>3</sup> to 10<sup>4</sup> actions.\n",
    "<br><br>\n",
    "<span class=\"fragment\" data-fragment-index=\"1\"><b>Partial  exploration</b> is used by SCB-LOLS ([Chang et al., 2015](https://arxiv.org/pdf/1502.02206.pdf)).</span><ul><li class=\"fragment\" data-fragment-index=\"1\">Randomly select time-steps and actions to rollout.</li></ul><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exploration variations ###\n",
    "\n",
    "<center>\n",
    "<img src=\"images/targetedExploration.png\">\n",
    "</center>\n",
    "\n",
    "Rollout for 50-200 time-steps, and 10<sup>3</sup> to 10<sup>4</sup> actions.\n",
    "<br><br>\n",
    "<span><b>Targeted exploration</b> is used by [Goodman et al. 2016](http://aclweb.org/anthology/P16-1001):</span><ul><li class=\"fragment\" data-fragment-index=\"3\">Perform rollout only for the expert policy action,</li><li class=\"fragment\" data-fragment-index=\"4\">and actions scored within a threshold $\\tau$ from the best.</li><br><li class=\"fragment\" data-fragment-index=\"5\">In first epoch (no classifier), randomly rollout actions.</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Targeted exploration results ###\n",
    "<h5>[Goodman et al. 2016](http://aclweb.org/anthology/P16-1001)</h5>\n",
    "<br><br>\n",
    "<center>\n",
    "<img src=\"images/amr_targetedExploration_results.png\" width=\"90%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step-level stochasticity ###\n",
    "\n",
    "V-DAgger and SEARN use step-level mix during roll-out.\n",
    "- Each rollout step either by <font color=\"blue\">classifier</font> or <font color=\"green\">expert</font>.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"images/stepStoch_1.png\">\n",
    "</center><br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Step-level stochasticity ###\n",
    "\n",
    "V-DAgger and SEARN use step-level mix during roll-out.\n",
    "- Each rollout step either by <font color=\"blue\">classifier</font> or <font color=\"green\">expert</font>.\n",
    "- Rollout on same $a$ may result on different sequence.\n",
    "<br><br>\n",
    "<center>\n",
    "<img src=\"images/stepStoch_1.png\">\n",
    "<img src=\"images/stepStoch_2.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Step-level stochasticity causes high variance in training signal.\n",
    "<ul><li class=\"fragment\" data-fragment-index=\"1\">Use LOLS instead?</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"images/perStepLOLS_1.png\">\n",
    "<img src=\"images/perStepLOLS_2.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<ul><li class=\"fragment\" data-fragment-index=\"1\">Sequence too long for full expert policy rollout.</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Focused costing ###\n",
    "\n",
    "Introduced by [Vlachos and Craven, 2011](http://www.aclweb.org/anthology/W/W11/W11-0307.pdf).<ul><li>Use the <font color=\"blue\">classifier</font> for first $b$ steps of rollout,</li><li>use <font color=\"green\">expert policy</font> for the rest.</li></ul>\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"images/perStepFocused.png\">\n",
    "</center>\n",
    "<br>\n",
    "<span class=\"fragment\" data-fragment-index=\"1\">Classifier costing focused on immediate actions.</span><ul><li class=\"fragment\" data-fragment-index=\"3\">No errors in distant actions of the rollout.</li><br><li class=\"fragment\" data-fragment-index=\"5\">Gradually increase $b$.</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Focused costing results ###\n",
    "<h5>[Goodman et al. 2016](http://aclweb.org/anthology/P16-1001)</h5>\n",
    "<br><br>\n",
    "<center>\n",
    "<img src=\"images/amr_focusedCosting_results.png\" width=\"50%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### $a$-bound ###\n",
    "\n",
    "Introduced by [Khardon and Wachman (2007)](http://www.jmlr.org/papers/volume8/khardon07a/khardon07a.pdf).\n",
    "\n",
    "Reduce training noise by ignoring noisy training instances.<br><br>\n",
    "<span class=\"fragment\" data-fragment-index=\"1\">During training, if the classifier makes > $a$ mistakes on a training instance:</span><ul><li class=\"fragment\" data-fragment-index=\"2\">Exclude instance from future training iterations.</li><li class=\"fragment\" data-fragment-index=\"3\">Related to Coaching (<a href=\"https://papers.nips.cc/paper/4545-imitation-learning-by-coaching.pdf\">He et al., 2012</a>)</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $\\alpha$-bound results ###\n",
    "<h5>[Goodman et al. 2016](http://aclweb.org/anthology/P16-1001)</h5>\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"images/aboundResults.png\" width=\"60%\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Comparison between IL approaches ###\n",
    "<h5>[Goodman et al. 2016](http://aclweb.org/anthology/P16-1001)</h5>\n",
    "\n",
    "<center>\n",
    "<img src=\"images/amrResults_otherIL.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Comparison against state of the art ###\n",
    "<h5>[Goodman et al. 2016](http://aclweb.org/anthology/P16-1001)</h5>\n",
    "\n",
    "<center>\n",
    "<img src=\"images/semParseRes.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Summary so far ### \n",
    "\n",
    "We discussed more modifications to the DAgger framework.\n",
    "- Targeted exploration consideres only actions for which the learned policy is uncertain and that disagree with the expert policy.\n",
    "- Using and $a$-bound we filter out training examples that confuse the classifier.\n",
    "- Focused costing performs the learned policy only on the actions that are immediately effected by the current explored one.\n",
    "\n",
    "We showed that imitation learning improves on the results."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "livereveal": {
   "height": 768,
   "start_slideshow_at": "selected",
   "theme": "solarized",
   "transition": "fade",
   "width": 1024
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
